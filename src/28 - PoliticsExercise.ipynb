{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Exercise\n",
    "\n",
    "## Predict political party based on votes\n",
    "\n",
    "As a fun little example, we'll use a public data set of how US congressmen voted on 17 different issues in the year 1984. Let's see if we can figure out their political party based on their votes alone, using a deep neural network!\n",
    "\n",
    "For those outside the United States, our two main political parties are \"Democrat\" and \"Republican.\" In modern times they represent progressive and conservative ideologies, respectively.\n",
    "\n",
    "Politics in 1984 weren't quite as polarized as they are today, but you should still be able to get over 90% accuracy without much trouble.\n",
    "\n",
    "Since the point of this exercise is implementing neural networks in Keras, I'll help you to load and prepare the data.\n",
    "\n",
    "Let's start by importing the raw CSV file using Pandas, and make a DataFrame out of it with nice column labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feature_names =  ['party','handicapped-infants', 'water-project-cost-sharing', \n",
    "                    'adoption-of-the-budget-resolution', 'physician-fee-freeze',\n",
    "                    'el-salvador-aid', 'religious-groups-in-schools',\n",
    "                    'anti-satellite-test-ban', 'aid-to-nicaraguan-contras',\n",
    "                    'mx-missle', 'immigration', 'synfuels-corporation-cutback',\n",
    "                    'education-spending', 'superfund-right-to-sue', 'crime',\n",
    "                    'duty-free-exports', 'export-administration-act-south-africa']\n",
    "\n",
    "voting_data = pd.read_csv('house-votes-84.data.txt', na_values=['?'], \n",
    "                          names = feature_names)\n",
    "voting_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use describe() to get a feel of how the data looks in aggregate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there's some missing data to deal with here; some politicians abstained on some votes, or just weren't present when the vote was taken. We will just drop the rows with missing data to keep it simple, but in practice you'd want to first make sure that doing so didn't introduce any sort of bias into your analysis (if one party abstains more than another, that could be problematic for example.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_data.dropna(inplace=True)\n",
    "voting_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our neural network needs normalized numbers, not strings, to work. So let's replace all the y's and n's with 1's and 0's, and represent the parties as 1's and 0's as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_data.replace(('y', 'n'), (1, 0), inplace=True)\n",
    "voting_data.replace(('democrat', 'republican'), (1, 0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's extract the features and labels in the form that Keras will expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = voting_data[feature_names].drop('party', axis=1).values\n",
    "all_classes = voting_data['party'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so have a go at it! You'll want to refer back to the slide on using Keras with binary classification - there are only two parties, so this is a binary problem. This also saves us the hassle of representing classes with \"one-hot\" format like we had to do with MNIST; our output is just a single 0 or 1 value.\n",
    "\n",
    "Also refer to the scikit_learn integration slide, and use cross_val_score to evaluate your resulting model with 10-fold cross-validation.\n",
    "\n",
    "Try out your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My implementation is below\n",
    "\n",
    "# No peeking!\n",
    "\n",
    "![title](peek.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    #16 feature inputs (votes) going into an 32-unit layer \n",
    "    model.add(Dense(32, input_dim=16, kernel_initializer='normal', activation='relu'))\n",
    "    # Another hidden layer of 16 units\n",
    "    model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
    "    # Output layer with a binary classification (Democrat or Republican political party)\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Wrap our Keras model in an estimator compatible with scikit_learn\n",
    "estimator = KerasClassifier(build_fn=create_model, nb_epoch=100, verbose=0)\n",
    "# Now we can use scikit_learn's cross_val_score to evaluate this model identically to the others\n",
    "cv_scores = cross_val_score(estimator, all_features, all_classes, cv=10)\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "91% without even trying too hard! Did you do better? Maybe more neurons, more layers, or Dropout layers would help even more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
